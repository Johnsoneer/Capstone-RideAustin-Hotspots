{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as msc\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "from bokeh.io import output_file, show, output_notebook\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, DataRange1d, PanTool, WheelZoomTool, BoxSelectTool\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = msc.connect(user='root', password='asdfghjkl;',\n",
    "                              host='127.0.0.1',\n",
    "                              database='rideaustin')\n",
    "df = pd.read_sql('SELECT start_location_lat,start_location_long, created_date,tod FROM rides  WHERE status = \"NO_AVAILABLE_DRIVER\" OR status = \"Completed\";', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['created_date'].dt.weekday\n",
    "df = df[(df['start_location_lat'] >= 30.190833) & (df['start_location_lat'] <= 30.404041)]\n",
    "df = df[(df['start_location_long'] >=-97.819014) & (df['start_location_long'] <= -97.647192)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def period(row):\n",
    "    '''\n",
    "    To be .apply() to dataframe with 'created_date' column. Takes in a row and creates a new column that\n",
    "    assigns that row to a particular 30 minute timeblock.\n",
    "    '''\n",
    "    timelables = list(range(0, 49))\n",
    "    timevalues = []\n",
    "    for x in list(range(0,25)):\n",
    "        timevalues.append((x,0))\n",
    "        timevalues.append((x,30))\n",
    "    periods = dict(zip(timelables, timevalues))\n",
    "    visit_start = {'hour': row.created_date.hour, 'min': row.created_date.minute} # get hour, min of visit start\n",
    "    for label, tupe in periods.items():\n",
    "        hour = tupe[0]\n",
    "        thirty = tupe[1]\n",
    "        if hour == visit_start['hour']:\n",
    "            if thirty <= visit_start['min'] <= thirty+30:\n",
    "                return label\n",
    "            else:\n",
    "                return label+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20489"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['period'] = df.apply(period, axis=1)\n",
    "dftest = df[(df['start_location_lat'] >= 30.252) & (df['start_location_lat'] <= 30.258)]\n",
    "dftest = dftest[(dftest['start_location_long'] <= -97.760) & (dftest['start_location_long'] >= -97.766)]\n",
    "#30.255456, -97.761994\n",
    "len(dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing centroid creator and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_centroids(dataframe):\n",
    "    ''' \n",
    "    Takes a dataframe of my start_location_lats and start_location_longs and builds a K-Means model with 5 centroids.\n",
    "    It returns a numpy array of the centroids (by lat-long pair) and a dictionary where the key is the centroid rank \n",
    "    and the value is a list of the [lat,long,# of datapoints, rank] for that centroid.\n",
    "    \n",
    "    INPUT:\n",
    "    - Dataframe\n",
    "    OUTPU:\n",
    "    - numpy array\n",
    "    - dictionary'''\n",
    "    if type(dataframe) == str:\n",
    "        return dataframe\n",
    "    X = np.array(dataframe[['start_location_lat','start_location_long']])\n",
    "    model = KMeans(n_clusters=5)\n",
    "    model.fit(X)\n",
    "    cents = model.cluster_centers_\n",
    "    lables_model = model.labels_\n",
    "    c = Counter(lables_model)\n",
    "    centroids_by_intensity = c.most_common(5)\n",
    "    ordered_labels = [i for i,x in centroids_by_intensity]\n",
    "    ordered_centroids = []\n",
    "    centroid_dict = {}\n",
    "\n",
    "    for i, index in enumerate(ordered_labels):\n",
    "        ordered_centroids.append(cents[index])\n",
    "        centroid_dict[i] = [cents[index][0],cents[index][1],centroids_by_intensity[i][1],i]\n",
    "    \n",
    "    return np.array(ordered_centroids), centroid_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_Austin_centroids(centroids, centroid_dictionary,num_datapoints, completed_rides=None, unfulfilled_rides=None):\n",
    "    '''\n",
    "    Takes in centroid values from create_centroids() and centroid_dictionary and plots the centroids relative to their\n",
    "    intensity. Optional inputs for the lat-long columns for completed_rides (green) and unfulfilled_rides(blue).\n",
    "    \n",
    "    INPUT:\n",
    "    - centroids (numpy array)\n",
    "    - centroid_dict (dictionary)\n",
    "    - copmleted_rides (dataframe)\n",
    "    - unfulfilled_rides (dataframe)\n",
    "    \n",
    "    OUTPUT:\n",
    "    -None\n",
    "    '''\n",
    "    #creating the plot\n",
    "    map_options = GMapOptions(lat=30.29, lng=-97.73, map_type=\"roadmap\", zoom=11)\n",
    "\n",
    "    plot = GMapPlot(\n",
    "        x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options\n",
    "    )\n",
    "    plot.title.text = \"Austin\"\n",
    "    plot.api_key = \"AIzaSyBx-cLXm4jxpg0aX_nnUnwd2hir3Ve0j9w\"\n",
    "    \n",
    "    #create alpha based on intensity\n",
    "    alpha = []\n",
    "    for key, value in centroid_dictionary.iteritems():\n",
    "        al_value = value[2]/float(num_datapoints)\n",
    "        al_fixed = al_value+.25\n",
    "        alpha.insert(key,al_fixed)\n",
    "    \n",
    "    #try if completed_rides is populated\n",
    "    try:\n",
    "        completed_lats = list(completed_rides['start_location_lat'])\n",
    "        completed_longs = list(completed_rides['start_location_long'])\n",
    "        completed_source = ColumnDataSource( data=dict(\n",
    "            lat=completed_lats,\n",
    "            lon=completed_longs,\n",
    "    )\n",
    ")\n",
    "        completed_dots = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"green\", fill_alpha=0.1, line_color=None)\n",
    "        plot.add_glyph(completed_source, completed_dots)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #try if unfulfilled_rides is populated\n",
    "    try:\n",
    "        unfulfilled_lats = list(unfulfilled_rides['start_location_lat'])\n",
    "        unfulfilled_longs = list(unfulfilled_rides['start_location_long'])\n",
    "        unfulfilled_source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            lat=unfulfilled_lats,\n",
    "            lon=unfulfilled_longs,\n",
    "\n",
    "        )\n",
    "    )\n",
    "        unfulfilled_dots = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"blue\", fill_alpha=0.8, line_color=None)\n",
    "        plot.add_glyph(unfulfilled_source, unfulfilled_dots)\n",
    "    except:\n",
    "        pass\n",
    "    #creating centroid source and circle\n",
    "    centroidlats = centroids[:,0]\n",
    "    centroidlongs = centroids[:,1]\n",
    "    centroid_source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            lat=centroidlats, \n",
    "            lon=centroidlongs,\n",
    "             alpha=alpha\n",
    "        )\n",
    "    )\n",
    "    centroid_dots = Circle(x=\"lon\", y=\"lat\", size=45, fill_color='#8B008B', fill_alpha='alpha', line_color=None)\n",
    "    plot.add_glyph(centroid_source, centroid_dots)\n",
    "    \n",
    "    #finishing the plot\n",
    "    plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool())\n",
    "    show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining 'Similar' pairs:\n",
    "- lat and long are within .006 of each other. \n",
    "- Weekdays are equal\n",
    "- timeblock within 1 of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_similar_pairs(dataframe,ride_request):\n",
    "    '''\n",
    "    Takes in a dataframe to test against and a ride request. Populates a distribution of other rides that\n",
    "    could follow that particular ride. \n",
    "\n",
    "     \n",
    "    input:\n",
    "    -original dataframe.values\n",
    "    -row (ndarray)\n",
    "    output:\n",
    "    -list of possible new points to sample from (Dataframe)\n",
    "    '''\n",
    "\n",
    "#     row2 = row2[['period','day_of_week', 'start_location_lat','start_location_long']].values\n",
    "    following_rides_list = []\n",
    "    row1 = ride_request\n",
    "    for i, request in enumerate(dataframe):\n",
    "        if row1[5] <= request[5] <= row1[5]+1 and row1[4] == request[4] \\\n",
    "        and row1[0] -.004 <= request[0] <= row1[0]+.004 \\\n",
    "        and row1[1]-.004 <= request[1] <= row1[1]+.004:\n",
    "#             request2 = dataframe[ind+1]\n",
    "#             if row2[0]-1 <= request2[0] <= row2[0]+1:# and row2[1] == request2[1] \\\n",
    "#             #and row2[2]-.006 <= request2[2] <= row2[2]+.006\\\n",
    "#             #and row2[3]-.006 <= request2[3] <= row2[3]+.006:\n",
    "            try:\n",
    "                request2 = dataframe[i+1]\n",
    "            except:\n",
    "                continue\n",
    "            following_rides_list.append(request2)\n",
    "    return pd.DataFrame(following_rides_list, columns=['start_location_lat','start_location_long','created_date',\\\n",
    "                                            'tod','day_of_week','period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_rides(input_dataframe):\n",
    "    '''\n",
    "    Takes in the most recent ride request and predicts the next half-hour worth of ride quests using\n",
    "    find_similar_pairs method.\n",
    "    \n",
    "    Inputs:\n",
    "    dataframe,\n",
    "    row,\n",
    "    n_rides (to be predicted in separate function)\n",
    "    \n",
    "    output:\n",
    "    Dataframe (predicted ride requests)'''\n",
    "    \n",
    "    predicted= []\n",
    "    last_ride = input_dataframe.tail(1)\n",
    "    datetime = last_ride['created_date']\n",
    "    last_ride = last_ride.values[0]\n",
    "    values = input_dataframe.values\n",
    "    n_rides = predict_n_rides(input_dataframe,datetime)\n",
    "    if n_rides < 20:\n",
    "        return \"not enough data to predict hotspots\"\n",
    "    for rep in xrange(n_rides):\n",
    "        distribution = find_similar_pairs(values,last_ride)\n",
    "        sample = distribution.sample().values\n",
    "        if len(sample) < 5:\n",
    "            sample = sample[0]\n",
    "        predicted.append(sample)\n",
    "        last_ride=sample\n",
    "    return pd.DataFrame(predicted, columns=['start_location_lat','start_location_long','created_date',\\\n",
    "                                            'tod','day_of_week','period'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         start_location_lat  start_location_long        created_date      tod  \\\n",
      "1145640            30.25591           -97.763143 2017-02-17 00:06:38 00:06:38   \n",
      "\n",
      "         day_of_week  period  \n",
      "1145640            4       0  \n"
     ]
    }
   ],
   "source": [
    "# rowal = doof[(doof['start_location_lat']>=30.253)&(doof['start_location_lat']<=30.257)]\n",
    "# rowal = rowal[(rowal['start_location_long']<=-97.761)&(rowal['start_location_long']>=-97.765)]\n",
    "# rowal = rowal.sample(1)\n",
    "print rowal\n",
    "rowal = rowal.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotting_df = doof.loc[:1145640]\n",
    "potential_followups = find_similar_pairs(plotting_df.values,rowal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_location_lat</th>\n",
       "      <th>start_location_long</th>\n",
       "      <th>created_date</th>\n",
       "      <th>tod</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>30.241155</td>\n",
       "      <td>-97.723861</td>\n",
       "      <td>2016-10-14 00:59:06</td>\n",
       "      <td>00:59:06</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_location_lat  start_location_long        created_date      tod  \\\n",
       "42           30.241155           -97.723861 2016-10-14 00:59:06 00:59:06   \n",
       "\n",
       "    day_of_week  period  \n",
       "42            4       1  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowal2 = potential_followups.sample(1)\n",
    "rowal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_options = GMapOptions(lat=30.29, lng=-97.73, map_type=\"roadmap\", zoom=11)\n",
    "completed_lats = potential_followups['start_location_lat']\n",
    "completed_longs = potential_followups[\"start_location_long\"]\n",
    "plot = GMapPlot(\n",
    "    x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options\n",
    ")\n",
    "plot.title.text = \"Austin\"\n",
    "plot.api_key = \"AIzaSyBx-cLXm4jxpg0aX_nnUnwd2hir3Ve0j9w\"\n",
    "\n",
    "#try if completed_rides is populated\n",
    "try:\n",
    "    completed_source = ColumnDataSource( data=dict(\n",
    "        lat=completed_lats,\n",
    "        lon=completed_longs,\n",
    ")\n",
    ")\n",
    "    completed_dots = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"green\", fill_alpha=0.5, line_color=None)\n",
    "    plot.add_glyph(completed_source, completed_dots)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#try if unfulfilled_rides is populated\n",
    "try:\n",
    "    unfulfilled_lats = list(unfulfilled_rides['start_location_lat'])\n",
    "    unfulfilled_longs = list(unfulfilled_rides['start_location_long'])\n",
    "    unfulfilled_source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=unfulfilled_lats,\n",
    "        lon=unfulfilled_longs,\n",
    "\n",
    "    )\n",
    ")\n",
    "    unfulfilled_dots = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"blue\", fill_alpha=0.8, line_color=None)\n",
    "    plot.add_glyph(unfulfilled_source, unfulfilled_dots)\n",
    "except:\n",
    "    pass\n",
    "#creating centroid source and circle\n",
    "\n",
    "centroid_source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=[30.255541,30.241155], \n",
    "        lon=[-97.763319,-97.723861],\n",
    "    )\n",
    ")\n",
    "centroid_dots = Circle(x=\"lon\", y=\"lat\", size=20, fill_color='blue', fill_alpha=.99, line_color=None)\n",
    "plot.add_glyph(centroid_source, centroid_dots)\n",
    "\n",
    "#finishing the plot\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool())\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.26128253 -97.74291888]\n",
      " [ 30.30877832 -97.72537264]\n",
      " [ 30.23537192 -97.78780446]\n",
      " [ 30.20242933 -97.66738067]\n",
      " [ 30.39011275 -97.74409875]]\n",
      "{0: [30.261282533129606, -97.742918879333942, 57, 0], 1: [30.308778319999998, -97.725372640000003, 20, 1], 2: [30.235371917774387, -97.787804464786021, 13, 2], 3: [30.202429333333335, -97.667380666666674, 6, 3], 4: [30.39011275, -97.744098750000006, 4, 4]}\n"
     ]
    }
   ],
   "source": [
    "predicted_centroids, predicted_dict = create_centroids(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.26128253  30.30877832  30.23537192  30.20242933  30.39011275]\n",
      "[0.82, 0.45, 0.38, 0.31, 0.29]\n"
     ]
    }
   ],
   "source": [
    "plot_Austin_centroids(predicted_centroids,predicted_dict,len(predictions),unfulfilled_rides=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mapping Rides Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_error(predicted_centroids,actual_centroids):\n",
    "    '''\n",
    "    takes in two sets of centroids and returns the average distance between each predicted centroid and the \n",
    "    closest actual centroid\n",
    "    \n",
    "    input:\n",
    "    -predicted ndarray\n",
    "    -actual ndarray\n",
    "    \n",
    "    output:\n",
    "    -float'''\n",
    "    \n",
    "    distances = []\n",
    "    for cent in predicted_centroids:\n",
    "        closest = 10000\n",
    "        for i in actual_centroids:\n",
    "            if vincenty(cent,i).miles < closest:\n",
    "                closest = vincenty(cent,i).miles\n",
    "        distances.append(closest)\n",
    "    return np.mean(distances)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_at_date(df,datetime):\n",
    "    '''\n",
    "    splits my dataset at anygiven datetime and parses the data into a training set of all rides that come before,\n",
    "    and the next 30 minutes \n",
    "    \n",
    "    input:\n",
    "    -Dataframe (all data)\n",
    "    - datetime obj (split location)\n",
    "    \n",
    "    output: \n",
    "    -X: dataframe\n",
    "    -X_test: dataframe\n",
    "    '''\n",
    "    datetime = pd.DataFrame([datetime], columns=['created_date'])\n",
    "    df1 = df[df['created_date']<=datetime['created_date'].iloc[0]]\n",
    "    df2 = df[(df['created_date']>=datetime['created_date'].iloc[0])&(df['created_date']<=datetime['created_date'].iloc[0]+pd.Timedelta('30 minute'))]\n",
    "    return df1,df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor for n_rides in a timeblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfreg = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfreg['month']= dfreg['created_date'].dt.month\n",
    "dfreg['day'] = dfreg['created_date'].dt.day\n",
    "dfreg['day_of_week'] = dfreg['created_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a COUNT response variable\n",
    "dfreg = dfreg.groupby(['day_of_week','period', 'month','day'])['start_location_lat'].count().reset_index(name=\"count\")\n",
    "#dfreg = pd.get_dummies(dfreg, columns=['day_of_week'], drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = dfreg.pop('count')\n",
    "X = dfreg\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for rf1: [-23.99056186 -22.80092167 -26.01468162]\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestRegressor(n_estimators=100)\n",
    "score = cross_val_score(rf1, X_train, y_train, scoring='neg_mean_absolute_error')\n",
    "print 'accuracy for rf1:', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1.fit(X_train,y_train)\n",
    "predictions = rf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.694990312759479"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime = pd.to_datetime('2016-10-09 11:00:00')\n",
    "d1,d2 = split_at_date(df,datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_rides(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 30.27576158, -97.73960623],\n",
       "        [ 30.25270348, -97.77019558],\n",
       "        [ 30.32715967, -97.71126918],\n",
       "        [ 30.23084577, -97.73083801],\n",
       "        [ 30.1998884 , -97.66664139]]),\n",
       " {0: [30.27576157986519, -97.739606232000185, 25, 0],\n",
       "  1: [30.252703483333335, -97.770195583333333, 12, 1],\n",
       "  2: [30.327159673220525, -97.711269178159867, 11, 2],\n",
       "  3: [30.230845771428569, -97.730838014285709, 7, 3],\n",
       "  4: [30.19988840426187, -97.666641393574963, 2, 4]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_centroids(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building functions to test model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_df(data):\n",
    "    '''\n",
    "    takes in dataframe of raw data and cleans it so that it can be passed into my model to predict n_rides for\n",
    "    the next half-hour block.\n",
    "    \n",
    "    input:\n",
    "    -dataframe\n",
    "    \n",
    "    output:\n",
    "    -X dataframe\n",
    "    -y dataframe'''\n",
    "    data['month']= data['created_date'].dt.month\n",
    "    data['day'] = data['created_date'].dt.day\n",
    "    data['day_of_week'] = data['created_date'].dt.weekday\n",
    "    # creating a COUNT response variable\n",
    "    data = data.groupby(['day_of_week','period','day'])['start_location_lat'].count().reset_index(name=\"count\")\n",
    "    #data = pd.get_dummies(data, columns=['day_of_week'], drop_first = True)\n",
    "    y = data.pop('count')\n",
    "    X = data\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_n_rides(data,datetime):\n",
    "    '''\n",
    "    takes in data and a split datetime and predicts how many n_rides there will be for the next half hour.\n",
    "    \n",
    "    input:\n",
    "    - data (dataframe)\n",
    "    - datime (string or datetime obj)\n",
    "    \n",
    "    output:\n",
    "    -int'''\n",
    "    data,response = prep_df(data)\n",
    "    rf1 = RandomForestRegressor(n_estimators=100)\n",
    "    model = rf1.fit(data,response)\n",
    "    data2, response2 = prep_df(d2)\n",
    "    n_rides = model.predict(data2).astype(int)[0] #return prediction as integer\n",
    "    if n_rides <= 10:\n",
    "        print \"Error: Not enough ride-traffic to predict hotspots.\"\n",
    "    return n_rides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model: 100 random dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_mean_dif_distribution(df):\n",
    "    '''\n",
    "    testing my model to find where the mean distance-error is. Use this distribution to create a hypo test to find \n",
    "    where the true mean is.\n",
    "    \n",
    "    input:\n",
    "    none\n",
    "    \n",
    "    output:\n",
    "    list of floats.'''\n",
    "    errors = []\n",
    "    for x in xrange(100):\n",
    "        #define parameters:\n",
    "        date = random_date()\n",
    "        dated = pd.to_datetime(date)\n",
    "        before,after = split_at_date(df,dated)\n",
    "        if len(after) <= 5:\n",
    "            continue\n",
    "        print 'date working: %s' %(date)\n",
    "        \n",
    "        # test_centroids:\n",
    "        test_centroids = create_centroids(after)\n",
    "        print 'test_centroids_working'\n",
    "        \n",
    "        #train_centroids:\n",
    "        try:\n",
    "            predictions = predict_rides(before)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        train_centroids = create_centroids(predictions)\n",
    "        if type(train_centroids) == str:\n",
    "            continue\n",
    "        print'train_centroids_working with %s predicted rides' %(len(predictions))\n",
    "        \n",
    "        #find error:\n",
    "        error = distance_error(train_centroids[0], test_centroids[0])\n",
    "        errors.append(error)\n",
    "        print 'completed error! %s' %(error)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_date():\n",
    "    year = 2016\n",
    "    month = random.randint(1, 12)\n",
    "    day = random.randint(1, 28)\n",
    "    hour = random.randint(0,23)\n",
    "    minute = random.randrange(0,31,30)\n",
    "    return '2016-%s-%s %s:%s:00' %(month,day,hour,minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date working: 2016-11-9 14:0:00\n",
      "test_centroids_working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_centroids_working with 40 predicted rides\n",
      "completed error! 1.46025521769\n",
      "date working: 2016-7-28 22:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-6 19:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-16 7:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-26 21:30:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-10-5 18:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-7-17 0:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-10-21 3:30:00\n",
      "test_centroids_working\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-9-10 16:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-9-18 4:30:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-7-5 3:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-7-8 7:30:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-11-27 16:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 37 predicted rides\n",
      "completed error! 1.35728586938\n",
      "date working: 2016-6-24 4:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-9-17 7:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-10-21 1:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 40 predicted rides\n",
      "completed error! 0.619884939436\n",
      "date working: 2016-7-27 1:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-28 8:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-11-13 1:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 40 predicted rides\n",
      "completed error! 1.17985578386\n",
      "date working: 2016-11-5 17:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 41 predicted rides\n",
      "completed error! 1.926244421\n",
      "date working: 2016-12-9 7:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 39 predicted rides\n",
      "completed error! 2.0732012946\n",
      "date working: 2016-9-15 18:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-12-8 0:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 38 predicted rides\n",
      "completed error! 1.04189200722\n",
      "date working: 2016-9-9 16:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-7-17 17:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-22 0:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-6-20 23:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-9-8 12:30:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-5 2:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-9-26 14:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-11-24 13:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 38 predicted rides\n",
      "completed error! 1.36590833174\n",
      "date working: 2016-11-2 21:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 40 predicted rides\n",
      "completed error! 1.75633963016\n",
      "date working: 2016-8-27 23:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-9-11 20:30:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-12-2 13:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 39 predicted rides\n",
      "completed error! 1.87666727951\n",
      "date working: 2016-8-5 14:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-6-20 23:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-7-21 13:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-23 20:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-11-2 3:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 41 predicted rides\n",
      "completed error! 1.48604268987\n",
      "date working: 2016-11-13 17:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 40 predicted rides\n",
      "completed error! 1.39915355662\n",
      "date working: 2016-12-8 21:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 39 predicted rides\n",
      "completed error! 1.09008951484\n",
      "date working: 2016-8-14 7:30:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-12-1 12:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 39 predicted rides\n",
      "completed error! 1.75725590293\n",
      "date working: 2016-10-10 18:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 41 predicted rides\n",
      "completed error! 1.08456014736\n",
      "date working: 2016-8-9 3:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n",
      "date working: 2016-8-15 21:0:00\n",
      "test_centroids_working\n",
      "Error: Not enough ride-traffic to predict hotspots.\n",
      "not enough data to predict hotspots\n"
     ]
    }
   ],
   "source": [
    "errors6 = create_mean_dif_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing mean error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.627209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.473275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.475026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.272163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.492028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.011780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.561892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  107.000000\n",
       "mean     1.627209\n",
       "std      0.473275\n",
       "min      0.475026\n",
       "25%      1.272163\n",
       "50%      1.492028\n",
       "75%      2.011780\n",
       "max      2.561892"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_errors = errors+errors2+errors3+errors4+errors5+errors6\n",
    "pd.DataFrame(total_errors).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "import scipy.stats as scs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing my observed errors from randomly generated hotspot predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11d144f90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnAjMzCruvwFoP835NletXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12db38c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(total_errors, bins=10)\n",
    "plt.xlabel('Mean Error in Miles')\n",
    "plt.ylabel('Frequency (120 samples)')\n",
    "plt.title('Distribution of Prediction Errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00844827241795\n"
     ]
    }
   ],
   "source": [
    "print 'p-value: %s' %(scs.ttest_1samp(a=total_errors, popmean=1.75)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# plotting predicted hotspots vs. actual rides\n",
    "date = '2017-4-13 20:00:00'\n",
    "dated = pd.to_datetime(date)\n",
    "df_june13,df_junetest =split_at_date(df,dated)\n",
    "predictions = predict_rides(df_june13)\n",
    "predicted_centroids,predicted_cent_dict = create_centroids(predictions)\n",
    "n_rides = predict_n_rides(df_june13,dated)\n",
    "plot_Austin_centroids(predicted_centroids,predicted_cent_dict,n_rides,unfulfilled_rides=df_junetest)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as msc\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "from bokeh.io import output_file, show, output_notebook\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, DataRange1d, PanTool, WheelZoomTool, BoxSelectTool\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from geopy.distance import vincenty\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = msc.connect(user='root', password='asdfghjkl;',\n",
    "                              host='127.0.0.1',\n",
    "                              database='rideaustin')\n",
    "df = pd.read_sql('SELECT start_location_lat,start_location_long, created_date,tod FROM rides  WHERE status = \"NO_AVAILABLE_DRIVER\" OR status = \"Completed\";', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['created_date'].dt.weekday\n",
    "df = df[(df['start_location_lat'] >= 30.190833) & (df['start_location_lat'] <= 30.404041)]\n",
    "df = df[(df['start_location_long'] >=-97.819014) & (df['start_location_long'] <= -97.647192)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def period(row):\n",
    "    '''\n",
    "    To be .apply() to dataframe with 'created_date' column. Takes in a row and creates a new column that\n",
    "    assigns that row to a particular 30 minute timeblock.\n",
    "    '''\n",
    "    timelables = list(range(0, 49))\n",
    "    timevalues = []\n",
    "    for x in list(range(0,25)):\n",
    "        timevalues.append((x,0))\n",
    "        timevalues.append((x,30))\n",
    "    periods = dict(zip(timelables, timevalues))\n",
    "    visit_start = {'hour': row.created_date.hour, 'min': row.created_date.minute} # get hour, min of visit start\n",
    "    for label, tupe in periods.items():\n",
    "        hour = tupe[0]\n",
    "        thirty = tupe[1]\n",
    "        if hour == visit_start['hour']:\n",
    "            if thirty <= visit_start['min'] <= thirty+30:\n",
    "                return label\n",
    "            else:\n",
    "                return label+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20489"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['period'] = df.apply(period, axis=1)\n",
    "dftest = df[(df['start_location_lat'] >= 30.252) & (df['start_location_lat'] <= 30.258)]\n",
    "dftest = dftest[(dftest['start_location_long'] <= -97.760) & (dftest['start_location_long'] >= -97.766)]\n",
    "#30.255456, -97.761994\n",
    "len(dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing centroid creator and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_centroids(dataframe):\n",
    "    ''' \n",
    "    Takes a dataframe of my start_location_lats and start_location_longs and builds a K-Means model with 5 centroids.\n",
    "    It returns a numpy array of the centroids (by lat-long pair) and a dictionary where the key is the centroid rank \n",
    "    and the value is a list of the [lat,long,# of datapoints, rank] for that centroid.\n",
    "    \n",
    "    INPUT:\n",
    "    - Dataframe\n",
    "    OUTPU:\n",
    "    - numpy array\n",
    "    - dictionary'''\n",
    "    X = np.array(dataframe[['start_location_lat','start_location_long']])\n",
    "    model = KMeans(n_clusters=5)\n",
    "    model.fit(X)\n",
    "    cents = model.cluster_centers_\n",
    "    lables_model = model.labels_\n",
    "    c = Counter(lables_model)\n",
    "    centroids_by_intensity = c.most_common(5)\n",
    "    ordered_labels = [i for i,x in centroids_by_intensity]\n",
    "    ordered_centroids = []\n",
    "    centroid_dict = {}\n",
    "\n",
    "    for i, index in enumerate(ordered_labels):\n",
    "        ordered_centroids.append(cents[index])\n",
    "        centroid_dict[i] = [cents[index][0],cents[index][1],centroids_by_intensity[i][1],i]\n",
    "    \n",
    "    return np.array(ordered_centroids), centroid_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_Austin_centroids(centroids, centroid_dictionary,num_datapoints, completed_rides=None, unfulfilled_rides=None):\n",
    "    '''\n",
    "    Takes in centroid values from create_centroids() and centroid_dictionary and plots the centroids relative to their\n",
    "    intensity. Optional inputs for the lat-long columns for completed_rides (green) and unfulfilled_rides(blue).\n",
    "    \n",
    "    INPUT:\n",
    "    - centroids (numpy array)\n",
    "    - centroid_dict (dictionary)\n",
    "    - copmleted_rides (dataframe)\n",
    "    - unfulfilled_rides (dataframe)\n",
    "    \n",
    "    OUTPUT:\n",
    "    -None\n",
    "    '''\n",
    "    #creating the plot\n",
    "    map_options = GMapOptions(lat=30.29, lng=-97.73, map_type=\"roadmap\", zoom=11)\n",
    "\n",
    "    plot = GMapPlot(\n",
    "        x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options\n",
    "    )\n",
    "    plot.title.text = \"Austin\"\n",
    "    plot.api_key = \"AIzaSyBx-cLXm4jxpg0aX_nnUnwd2hir3Ve0j9w\"\n",
    "    \n",
    "    #create alpha based on intensity\n",
    "    alpha = []\n",
    "    for key, value in centroid_dictionary.iteritems():\n",
    "        al_value = value[2]/float(num_datapoints)\n",
    "        al_fixed = al_value+.25\n",
    "        alpha.insert(key,al_fixed)\n",
    "    \n",
    "    #try if completed_rides is populated\n",
    "    try:\n",
    "        completed_lats = list(completed_rides['start_location_lat'])\n",
    "        completed_longs = list(completed_rides['start_location_long'])\n",
    "        completed_source = ColumnDataSource( data=dict(\n",
    "            lat=completed_lats,\n",
    "            lon=completed_longs,\n",
    "    )\n",
    ")\n",
    "        completed_dots = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"green\", fill_alpha=0.1, line_color=None)\n",
    "        plot.add_glyph(completed_source, completed_dots)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #try if unfulfilled_rides is populated\n",
    "    try:\n",
    "        unfulfilled_lats = list(unfulfilled_rides['start_location_lat'])\n",
    "        unfulfilled_longs = list(unfulfilled_rides['start_location_long'])\n",
    "        unfulfilled_source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            lat=unfulfilled_lats,\n",
    "            lon=unfulfilled_longs,\n",
    "\n",
    "        )\n",
    "    )\n",
    "        unfulfilled_dots = Circle(x=\"lon\", y=\"lat\", size=15, fill_color=\"blue\", fill_alpha=0.8, line_color=None)\n",
    "        plot.add_glyph(unfulfilled_source, unfulfilled_dots)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #creating centroid source and circle\n",
    "    centroidlats = centroids[:,0]\n",
    "    centroidlongs = centroids[:,1]\n",
    "    centroid_source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            lat=centroidlats, \n",
    "            lon=centroidlongs,\n",
    "             alpha=alpha\n",
    "        )\n",
    "    )\n",
    "    centroid_dots = Circle(x=\"lon\", y=\"lat\", size=45, fill_color='#8B008B', fill_alpha='alpha', line_color=None)\n",
    "    plot.add_glyph(centroid_source, centroid_dots)\n",
    "    \n",
    "    #finishing the plot\n",
    "    plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool())\n",
    "    show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining 'Similar' pairs:\n",
    "- lat and long are within .006 of each other. \n",
    "- Weekdays are equal\n",
    "- timeblock within 1 of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_similar_pairs(dataframe,ride_request):\n",
    "    '''\n",
    "    Takes in a dataframe to test against and a ride request. Populates a distribution of other rides that\n",
    "    could follow that particular ride. \n",
    "\n",
    "     \n",
    "    input:\n",
    "    -original dataframe.values\n",
    "    -row (ndarray)\n",
    "    output:\n",
    "    -list of possible new points to sample from (Dataframe)\n",
    "    '''\n",
    "\n",
    "#     row2 = row2[['period','day_of_week', 'start_location_lat','start_location_long']].values\n",
    "    following_rides_list = []\n",
    "    row1 = ride_request\n",
    "    for i, request in enumerate(dataframe):\n",
    "        if row1[5] <= request[5] <= row1[5]+1 and row1[4] == request[4] \\\n",
    "        and row1[0] -.003 <= request[0] <= row1[0]+.003 \\\n",
    "        and row1[1]-.003 <= request[1] <= row1[1]+.003:\n",
    "#             request2 = dataframe[ind+1]\n",
    "#             if row2[0]-1 <= request2[0] <= row2[0]+1:# and row2[1] == request2[1] \\\n",
    "#             #and row2[2]-.006 <= request2[2] <= row2[2]+.006\\\n",
    "#             #and row2[3]-.006 <= request2[3] <= row2[3]+.006:\n",
    "            try:\n",
    "                request2 = dataframe[i+1]\n",
    "            except:\n",
    "                continue\n",
    "            following_rides_list.append(request2)\n",
    "    return pd.DataFrame(following_rides_list, columns=['start_location_lat','start_location_long','created_date',\\\n",
    "                                            'tod','day_of_week','period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rides(input_dataframe):\n",
    "    '''\n",
    "    Takes in the most recent ride request and predicts the next half-hour worth of ride quests using\n",
    "    find_similar_pairs method.\n",
    "    \n",
    "    Inputs:\n",
    "    dataframe,\n",
    "    row,\n",
    "    n_rides (to be predicted in separate function)\n",
    "    \n",
    "    output:\n",
    "    Dataframe (predicted ride requests)'''\n",
    "    \n",
    "    predicted= []\n",
    "    last_ride = input_dataframe.tail(1)\n",
    "    datetime = last_ride['created_date']\n",
    "    last_ride = last_ride.values[0]\n",
    "    values = input_dataframe.values\n",
    "    n_rides = predict_n_rides(input_dataframe,datetime)\n",
    "    if n_rides <= 30:\n",
    "        n_rides = 30\n",
    "    for rep in xrange(n_rides):\n",
    "        distribution = find_similar_pairs(values,last_ride)\n",
    "        sample = distribution.sample().values\n",
    "        if len(sample) < 5:\n",
    "            sample = sample[0]\n",
    "        predicted.append(sample)\n",
    "        last_ride=sample\n",
    "    return pd.DataFrame(predicted, columns=['start_location_lat','start_location_long','created_date',\\\n",
    "                                            'tod','day_of_week','period'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "[30.267072 -97.740337 Timestamp('2017-01-20 01:24:37')\n",
      " Timedelta('0 days 01:24:37') 4 2]\n",
      "[30.269913737750787 -97.73154895752668 Timestamp('2016-12-16 01:48:30')\n",
      " Timedelta('0 days 01:48:30') 4 3]\n",
      "[30.334579 -97.721451 Timestamp('2016-09-30 02:25:35')\n",
      " Timedelta('0 days 02:25:35') 4 4]\n",
      "[30.286272 -97.750332 Timestamp('2017-04-07 02:36:51')\n",
      " Timedelta('0 days 02:36:51') 4 5]\n",
      "[30.268955 -97.731884 Timestamp('2017-01-20 02:51:14')\n",
      " Timedelta('0 days 02:51:14') 4 5]\n",
      "[30.236477 -97.718735 Timestamp('2016-09-23 03:20:08')\n",
      " Timedelta('0 days 03:20:08') 4 6]\n",
      "[30.268052 -97.763952 Timestamp('2016-11-18 03:47:27')\n",
      " Timedelta('0 days 03:47:27') 4 7]\n",
      "[30.263594 -97.763319 Timestamp('2016-12-23 04:05:22')\n",
      " Timedelta('0 days 04:05:22') 4 8]\n",
      "[30.201536 -97.771383 Timestamp('2017-04-14 04:00:35')\n",
      " Timedelta('0 days 04:00:35') 4 8]\n",
      "[30.289776 -97.758666 Timestamp('2017-01-06 04:58:55')\n",
      " Timedelta('0 days 04:58:55') 4 9]\n",
      "[30.290408 -97.748778 Timestamp('2017-04-07 04:31:14')\n",
      " Timedelta('0 days 04:31:14') 4 9]\n",
      "[30.269911 -97.749462 Timestamp('2017-02-03 05:15:38')\n",
      " Timedelta('0 days 05:15:38') 4 10]\n",
      "[30.249085 -97.750044 Timestamp('2016-12-02 05:06:04')\n",
      " Timedelta('0 days 05:06:04') 4 10]\n",
      "[30.270356 -97.749884 Timestamp('2017-03-17 05:30:10')\n",
      " Timedelta('0 days 05:30:10') 4 10]\n",
      "[30.266686 -97.753358 Timestamp('2017-03-10 05:09:01')\n",
      " Timedelta('0 days 05:09:01') 4 10]\n",
      "[30.266916 -97.735193 Timestamp('2016-10-07 05:06:22')\n",
      " Timedelta('0 days 05:06:22') 4 10]\n",
      "[30.267214 -97.736022 Timestamp('2016-12-16 05:09:44')\n",
      " Timedelta('0 days 05:09:44') 4 10]\n",
      "[30.271926 -97.754576 Timestamp('2017-02-10 05:10:05')\n",
      " Timedelta('0 days 05:10:05') 4 10]\n",
      "[30.269986 -97.750206 Timestamp('2016-09-30 05:20:36')\n",
      " Timedelta('0 days 05:20:36') 4 10]\n",
      "[30.251737816738604 -97.76396848261358 Timestamp('2016-11-11 05:38:12')\n",
      " Timedelta('0 days 05:38:12') 4 11]\n",
      "[30.292046100000007 -97.723447 Timestamp('2017-03-17 05:43:55')\n",
      " Timedelta('0 days 05:43:55') 4 11]\n",
      "[30.266508 -97.738716 Timestamp('2017-03-10 05:47:55')\n",
      " Timedelta('0 days 05:47:55') 4 11]\n",
      "[30.255175 -97.73763 Timestamp('2017-01-27 06:14:41')\n",
      " Timedelta('0 days 06:14:41') 4 12]\n",
      "[30.264971 -97.731591 Timestamp('2017-03-17 06:45:04')\n",
      " Timedelta('0 days 06:45:04') 4 13]\n",
      "[30.267249 -97.738176 Timestamp('2017-03-17 06:38:46')\n",
      " Timedelta('0 days 06:38:46') 4 13]\n",
      "[30.257508 -97.766478 Timestamp('2016-11-25 06:42:10')\n",
      " Timedelta('0 days 06:42:10') 4 13]\n",
      "[30.27411 -97.719744 Timestamp('2016-12-30 06:44:19')\n",
      " Timedelta('0 days 06:44:19') 4 13]\n",
      "[30.267267 -97.736794 Timestamp('2017-01-27 06:46:14')\n",
      " Timedelta('0 days 06:46:14') 4 13]\n",
      "[30.263424 -97.727236 Timestamp('2017-03-10 07:30:54')\n",
      " Timedelta('0 days 07:30:54') 4 14]\n",
      "[30.28756 -97.746343 Timestamp('2017-02-24 07:49:54')\n",
      " Timedelta('0 days 07:49:54') 4 15]\n",
      "[30.270647 -97.74703 Timestamp('2016-10-07 07:43:20')\n",
      " Timedelta('0 days 07:43:20') 4 15]\n",
      "[30.268026 -97.738947 Timestamp('2017-01-27 08:09:28')\n",
      " Timedelta('0 days 08:09:28') 4 16]\n",
      "[30.266553 -97.73734 Timestamp('2017-02-24 08:44:08')\n",
      " Timedelta('0 days 08:44:08') 4 17]\n",
      "[30.268829 -97.738649 Timestamp('2017-01-20 08:38:12')\n",
      " Timedelta('0 days 08:38:12') 4 17]\n",
      "[30.289456 -97.748762 Timestamp('2017-02-03 08:40:32')\n",
      " Timedelta('0 days 08:40:32') 4 17]\n",
      "[30.242598 -97.780775 Timestamp('2017-03-31 09:25:28')\n",
      " Timedelta('0 days 09:25:28') 4 18]\n",
      "[30.267739 -97.739883 Timestamp('2016-11-18 09:59:00')\n",
      " Timedelta('0 days 09:59:00') 4 19]\n",
      "[30.253137 -97.716596 Timestamp('2016-12-23 09:32:12')\n",
      " Timedelta('0 days 09:32:12') 4 19]\n",
      "[30.290556 -97.733527 Timestamp('2017-03-10 09:58:59')\n",
      " Timedelta('0 days 09:58:59') 4 19]\n",
      "[30.244555 -97.773772 Timestamp('2016-12-30 10:23:23')\n",
      " Timedelta('0 days 10:23:23') 4 20]\n",
      "[30.275374 -97.76356 Timestamp('2016-08-19 10:09:31')\n",
      " Timedelta('0 days 10:09:31') 4 20]\n",
      "[30.252742 -97.724946 Timestamp('2017-02-10 10:02:06')\n",
      " Timedelta('0 days 10:02:06') 4 20]\n",
      "[30.251974 -97.727484 Timestamp('2016-11-11 10:56:23')\n",
      " Timedelta('0 days 10:56:23') 4 21]\n",
      "[30.214563 -97.753745 Timestamp('2016-10-07 11:10:34')\n",
      " Timedelta('0 days 11:10:34') 4 22]\n",
      "[30.274502 -97.765019 Timestamp('2016-10-07 11:12:13')\n",
      " Timedelta('0 days 11:12:13') 4 22]\n",
      "[30.293992 -97.746104 Timestamp('2016-10-07 11:15:24')\n",
      " Timedelta('0 days 11:15:24') 4 22]\n",
      "[30.274336 -97.718486 Timestamp('2017-04-07 11:20:27')\n",
      " Timedelta('0 days 11:20:27') 4 22]\n",
      "[30.301915 -97.737187 Timestamp('2017-03-10 11:29:12')\n",
      " Timedelta('0 days 11:29:12') 4 22]\n",
      "[30.2595 -97.747911 Timestamp('2017-03-17 11:51:23')\n",
      " Timedelta('0 days 11:51:23') 4 23]\n",
      "[30.369821 -97.744975 Timestamp('2016-10-28 12:21:22')\n",
      " Timedelta('0 days 12:21:22') 4 24]\n",
      "[30.288126 -97.743425 Timestamp('2016-12-02 12:08:02')\n",
      " Timedelta('0 days 12:08:02') 4 24]\n",
      "[30.214405 -97.750545 Timestamp('2017-04-07 12:45:35')\n",
      " Timedelta('0 days 12:45:35') 4 25]\n",
      "[30.318134 -97.708828 Timestamp('2016-11-11 12:55:29')\n",
      " Timedelta('0 days 12:55:29') 4 25]\n",
      "[30.269084 -97.751545 Timestamp('2016-09-09 13:09:49')\n",
      " Timedelta('0 days 13:09:49') 4 26]\n",
      "[30.19321 -97.777007 Timestamp('2017-03-10 13:07:41')\n",
      " Timedelta('0 days 13:07:41') 4 26]\n",
      "[30.250929199118964 -97.74948086589575 Timestamp('2017-02-17 13:42:42')\n",
      " Timedelta('0 days 13:42:42') 4 27]\n",
      "[30.261524 -97.773755 Timestamp('2016-12-02 13:41:17')\n",
      " Timedelta('0 days 13:41:17') 4 27]\n",
      "[30.228571994100687 -97.72397574037315 Timestamp('2016-11-18 13:37:10')\n",
      " Timedelta('0 days 13:37:10') 4 27]\n",
      "[30.300708 -97.696142 Timestamp('2017-03-31 14:26:18')\n",
      " Timedelta('0 days 14:26:18') 4 28]\n",
      "[30.232222 -97.716708 Timestamp('2016-09-23 14:30:00')\n",
      " Timedelta('0 days 14:30:00') 4 28]\n",
      "[30.301972 -97.734481 Timestamp('2017-03-24 14:46:27')\n",
      " Timedelta('0 days 14:46:27') 4 29]\n",
      "[30.301972 -97.734481 Timestamp('2017-03-24 14:46:48')\n",
      " Timedelta('0 days 14:46:48') 4 29]\n",
      "[30.234359 -97.724444 Timestamp('2017-01-13 14:42:35')\n",
      " Timedelta('0 days 14:42:35') 4 29]\n",
      "[30.323358 -97.68671 Timestamp('2017-01-20 15:13:22')\n",
      " Timedelta('0 days 15:13:22') 4 30]\n",
      "[30.272238 -97.731161 Timestamp('2017-01-20 15:13:36')\n",
      " Timedelta('0 days 15:13:36') 4 30]\n",
      "[30.202989 -97.666823 Timestamp('2017-03-24 15:31:44')\n",
      " Timedelta('0 days 15:31:44') 4 31]\n",
      "[30.267168 -97.749292 Timestamp('2017-04-07 16:31:03')\n",
      " Timedelta('0 days 16:31:03') 4 33]\n",
      "[30.273053 -97.768678 Timestamp('2017-01-20 16:54:16')\n",
      " Timedelta('0 days 16:54:16') 4 33]\n",
      "[30.289748 -97.74941 Timestamp('2017-01-20 16:55:08')\n",
      " Timedelta('0 days 16:55:08') 4 33]\n",
      "[30.202579 -97.667154 Timestamp('2017-02-03 16:32:09')\n",
      " Timedelta('0 days 16:32:09') 4 33]\n",
      "[30.24713 -97.73156 Timestamp('2017-03-10 16:54:51')\n",
      " Timedelta('0 days 16:54:51') 4 33]\n",
      "[30.246688 -97.754115 Timestamp('2017-03-17 16:45:41')\n",
      " Timedelta('0 days 16:45:41') 4 33]\n",
      "[30.337056730576883 -97.69981406629086 Timestamp('2016-09-16 16:49:14')\n",
      " Timedelta('0 days 16:49:14') 4 33]\n",
      "[30.3552655 -97.75164740000001 Timestamp('2017-01-27 17:30:31')\n",
      " Timedelta('0 days 17:30:31') 4 34]\n",
      "[30.232884 -97.737872 Timestamp('2017-03-17 17:32:51')\n",
      " Timedelta('0 days 17:32:51') 4 35]\n",
      "[30.320498 -97.731961 Timestamp('2017-03-17 17:59:50')\n",
      " Timedelta('0 days 17:59:50') 4 35]\n",
      "[30.29539 -97.767967 Timestamp('2016-09-30 18:17:15')\n",
      " Timedelta('0 days 18:17:15') 4 36]\n",
      "[30.278825 -97.716289 Timestamp('2016-09-30 18:12:23')\n",
      " Timedelta('0 days 18:12:23') 4 36]\n",
      "[30.307243 -97.696285 Timestamp('2016-09-30 18:14:48')\n",
      " Timedelta('0 days 18:14:48') 4 36]\n",
      "[30.238089 -97.713213 Timestamp('2016-10-07 18:34:28')\n",
      " Timedelta('0 days 18:34:28') 4 37]\n",
      "[30.28155 -97.77498 Timestamp('2017-04-14 19:15:04')\n",
      " Timedelta('0 days 19:15:04') 4 38]\n",
      "[30.320762 -97.77334 Timestamp('2017-02-17 19:46:17')\n",
      " Timedelta('0 days 19:46:17') 4 39]\n",
      "[30.264827 -97.739215 Timestamp('2017-03-17 19:40:22')\n",
      " Timedelta('0 days 19:40:22') 4 39]\n",
      "[30.252278 -97.748878 Timestamp('2016-10-28 20:04:21')\n",
      " Timedelta('0 days 20:04:21') 4 40]\n",
      "[30.319639 -97.755025 Timestamp('2016-09-30 20:03:17')\n",
      " Timedelta('0 days 20:03:17') 4 40]\n",
      "[30.271935 -97.753434 Timestamp('2016-09-30 20:57:57')\n",
      " Timedelta('0 days 20:57:57') 4 41]\n",
      "[30.238639800000005 -97.71732779999999 Timestamp('2017-03-03 21:28:51')\n",
      " Timedelta('0 days 21:28:51') 4 42]\n",
      "[30.346951 -97.714222 Timestamp('2016-12-16 21:21:17')\n",
      " Timedelta('0 days 21:21:17') 4 42]\n",
      "[30.277541 -97.742544 Timestamp('2017-04-14 21:18:00')\n",
      " Timedelta('0 days 21:18:00') 4 42]\n",
      "[30.268986 -97.75415 Timestamp('2017-04-14 21:18:01')\n",
      " Timedelta('0 days 21:18:01') 4 42]\n",
      "[30.229761 -97.749438 Timestamp('2016-10-07 21:24:18')\n",
      " Timedelta('0 days 21:24:18') 4 42]\n",
      "[30.278858 -97.710255 Timestamp('2016-10-07 21:30:05')\n",
      " Timedelta('0 days 21:30:05') 4 42]\n",
      "[30.268168 -97.797071 Timestamp('2017-03-17 21:15:46')\n",
      " Timedelta('0 days 21:15:46') 4 42]\n",
      "[30.256684 -97.752494 Timestamp('2016-11-04 21:58:09')\n",
      " Timedelta('0 days 21:58:09') 4 43]\n",
      "[30.300147 -97.719948 Timestamp('2017-02-24 22:21:15')\n",
      " Timedelta('0 days 22:21:15') 4 44]\n",
      "[30.266362 -97.747872 Timestamp('2017-02-03 22:50:52')\n",
      " Timedelta('0 days 22:50:52') 4 45]\n",
      "[30.277428 -97.74258 Timestamp('2017-04-14 23:01:06')\n",
      " Timedelta('0 days 23:01:06') 4 46]\n",
      "[30.299479 -97.793039 Timestamp('2016-10-21 23:58:28')\n",
      " Timedelta('0 days 23:58:28') 4 47]\n",
      "[30.303923 -97.712317 Timestamp('2017-03-10 23:37:02')\n",
      " Timedelta('0 days 23:37:02') 4 47]\n",
      "[30.296867 -97.752233 Timestamp('2016-07-29 23:50:53')\n",
      " Timedelta('0 days 23:50:53') 4 47]\n",
      "[30.375102758084257 -97.70547989755869 Timestamp('2017-04-14 23:50:48')\n",
      " Timedelta('0 days 23:50:48') 4 47]\n",
      "[30.332122 -97.744244 Timestamp('2016-11-04 23:38:01')\n",
      " Timedelta('0 days 23:38:01') 4 47]\n",
      "[30.238066 -97.784435 Timestamp('2016-12-02 23:38:38')\n",
      " Timedelta('0 days 23:38:38') 4 47]\n",
      "[30.24472 -97.764116 Timestamp('2016-07-22 23:40:37')\n",
      " Timedelta('0 days 23:40:37') 4 47]\n",
      "[30.269464 -97.748736 Timestamp('2016-12-09 23:32:46')\n",
      " Timedelta('0 days 23:32:46') 4 47]\n",
      "[30.30998 -97.681524 Timestamp('2017-03-31 23:46:42')\n",
      " Timedelta('0 days 23:46:42') 4 47]\n",
      "[30.260814 -97.738219 Timestamp('2017-02-24 23:52:18')\n",
      " Timedelta('0 days 23:52:18') 4 47]\n",
      "[30.391828 -97.749905 Timestamp('2016-10-28 23:49:32')\n",
      " Timedelta('0 days 23:49:32') 4 47]\n",
      "[30.314833 -97.73597 Timestamp('2016-12-30 23:33:21')\n",
      " Timedelta('0 days 23:33:21') 4 47]\n",
      "[30.246361 -97.758393 Timestamp('2016-12-16 23:45:57')\n",
      " Timedelta('0 days 23:45:57') 4 47]\n",
      "[30.264505 -97.745421 Timestamp('2016-07-15 23:41:39')\n",
      " Timedelta('0 days 23:41:39') 4 47]\n",
      "[30.28318 -97.73405 Timestamp('2016-12-09 23:58:46')\n",
      " Timedelta('0 days 23:58:46') 4 47]\n",
      "[30.241048 -97.74778 Timestamp('2016-11-25 23:48:03')\n",
      " Timedelta('0 days 23:48:03') 4 47]\n",
      "[30.256027 -97.742883 Timestamp('2016-08-12 23:51:28')\n",
      " Timedelta('0 days 23:51:28') 4 47]\n",
      "[30.372342 -97.760531 Timestamp('2016-12-30 23:44:52')\n",
      " Timedelta('0 days 23:44:52') 4 47]\n",
      "[30.261102 -97.758505 Timestamp('2016-09-30 23:56:11')\n",
      " Timedelta('0 days 23:56:11') 4 47]\n",
      "[30.265659 -97.738448 Timestamp('2017-01-20 23:50:21')\n",
      " Timedelta('0 days 23:50:21') 4 47]\n",
      "[30.26696 -97.745692 Timestamp('2017-01-20 23:38:14')\n",
      " Timedelta('0 days 23:38:14') 4 47]\n",
      "[30.326972 -97.705272 Timestamp('2016-11-04 23:31:16')\n",
      " Timedelta('0 days 23:31:16') 4 47]\n",
      "[30.294053 -97.760904 Timestamp('2016-11-04 23:44:54')\n",
      " Timedelta('0 days 23:44:54') 4 47]\n",
      "[30.281452 -97.736048 Timestamp('2016-10-14 23:55:55')\n",
      " Timedelta('0 days 23:55:55') 4 47]\n",
      "[30.264412 -97.743564 Timestamp('2016-10-07 23:33:37')\n",
      " Timedelta('0 days 23:33:37') 4 47]\n",
      "[30.306532 -97.732444 Timestamp('2017-01-06 23:45:04')\n",
      " Timedelta('0 days 23:45:04') 4 47]\n",
      "[30.265836 -97.748525 Timestamp('2016-07-22 23:44:13')\n",
      " Timedelta('0 days 23:44:13') 4 47]\n",
      "[30.283426 -97.717271 Timestamp('2016-11-04 23:55:31')\n",
      " Timedelta('0 days 23:55:31') 4 47]\n",
      "[30.30783 -97.729309 Timestamp('2017-03-24 23:51:45')\n",
      " Timedelta('0 days 23:51:45') 4 47]\n",
      "[30.192167 -97.737789 Timestamp('2017-04-07 23:45:56')\n",
      " Timedelta('0 days 23:45:56') 4 47]\n",
      "[30.296963 -97.712524 Timestamp('2017-04-07 23:45:56')\n",
      " Timedelta('0 days 23:45:56') 4 47]\n",
      "[30.321854 -97.719219 Timestamp('2016-12-09 23:56:58')\n",
      " Timedelta('0 days 23:56:58') 4 47]\n",
      "[30.262775 -97.793845 Timestamp('2016-10-07 23:31:29')\n",
      " Timedelta('0 days 23:31:29') 4 47]\n",
      "[30.258942 -97.808572 Timestamp('2017-03-03 23:41:24')\n",
      " Timedelta('0 days 23:41:24') 4 47]\n",
      "[30.218554 -97.726148 Timestamp('2017-03-24 23:53:15')\n",
      " Timedelta('0 days 23:53:15') 4 47]\n",
      "[30.399067 -97.724946 Timestamp('2017-03-24 23:53:16')\n",
      " Timedelta('0 days 23:53:16') 4 47]\n",
      "[30.26845200425862 -97.7439709380269 Timestamp('2017-03-17 23:50:21')\n",
      " Timedelta('0 days 23:50:21') 4 47]\n",
      "[30.258032 -97.807275 Timestamp('2016-09-23 23:31:46')\n",
      " Timedelta('0 days 23:31:46') 4 47]\n",
      "[30.252846 -97.766544 Timestamp('2016-07-01 23:41:35')\n",
      " Timedelta('0 days 23:41:35') 4 47]\n",
      "[30.260016 -97.73918 Timestamp('2017-02-03 23:41:13')\n",
      " Timedelta('0 days 23:41:13') 4 47]\n",
      "[30.194156999999993 -97.769114 Timestamp('2017-01-27 23:31:53')\n",
      " Timedelta('0 days 23:31:53') 4 47]\n",
      "[30.26875778865947 -97.7537901699543 Timestamp('2017-01-27 23:32:04')\n",
      " Timedelta('0 days 23:32:04') 4 47]\n",
      "[30.294512 -97.744353 Timestamp('2017-04-07 23:54:02')\n",
      " Timedelta('0 days 23:54:02') 4 47]\n",
      "[30.299467 -97.732876 Timestamp('2016-09-10 00:00:07')\n",
      " Timedelta('0 days 00:00:07') 5 0]\n",
      "[30.2693 -97.73708 Timestamp('2017-02-25 00:48:13')\n",
      " Timedelta('0 days 00:48:13') 5 1]\n",
      "[30.276393 -97.718098 Timestamp('2017-04-01 01:05:43')\n",
      " Timedelta('0 days 01:05:43') 5 2]\n",
      "[30.262528 -97.741302 Timestamp('2017-03-18 01:48:55')\n",
      " Timedelta('0 days 01:48:55') 5 3]\n",
      "[30.30723 -97.67313 Timestamp('2017-03-25 01:35:32')\n",
      " Timedelta('0 days 01:35:32') 5 3]\n",
      "[30.260052 -97.739111 Timestamp('2016-11-19 01:31:34')\n",
      " Timedelta('0 days 01:31:34') 5 3]\n",
      "[30.268267 -97.732049 Timestamp('2016-07-02 02:19:16')\n",
      " Timedelta('0 days 02:19:16') 5 4]\n",
      "[30.264876 -97.7633 Timestamp('2016-07-02 02:02:18')\n",
      " Timedelta('0 days 02:02:18') 5 4]\n",
      "[30.282447 -97.680996 Timestamp('2017-02-04 02:16:45')\n",
      " Timedelta('0 days 02:16:45') 5 4]\n",
      "[30.289187599999995 -97.7690568 Timestamp('2017-02-11 02:17:18')\n",
      " Timedelta('0 days 02:17:18') 5 4]\n",
      "[30.202881 -97.667746 Timestamp('2017-01-07 02:56:27')\n",
      " Timedelta('0 days 02:56:27') 5 5]\n",
      "[30.293984 -97.720996 Timestamp('2017-01-28 02:47:13')\n",
      " Timedelta('0 days 02:47:13') 5 5]\n",
      "[30.251595 -97.749416 Timestamp('2017-03-18 03:02:08')\n",
      " Timedelta('0 days 03:02:08') 5 6]\n",
      "[30.261482989083227 -97.72680815309286 Timestamp('2017-01-21 03:04:16')\n",
      " Timedelta('0 days 03:04:16') 5 6]\n",
      "[30.257248 -97.702809 Timestamp('2017-04-08 03:12:58')\n",
      " Timedelta('0 days 03:12:58') 5 6]\n",
      "[30.266255 -97.740658 Timestamp('2017-04-15 03:28:03')\n",
      " Timedelta('0 days 03:28:03') 5 6]\n",
      "[30.298909 -97.708545 Timestamp('2017-03-11 03:53:35')\n",
      " Timedelta('0 days 03:53:35') 5 7]\n",
      "[30.268239 -97.747502 Timestamp('2017-02-04 04:24:50')\n",
      " Timedelta('0 days 04:24:50') 5 8]\n",
      "[30.287386543318682 -97.74739947170019 Timestamp('2016-10-15 04:40:49')\n",
      " Timedelta('0 days 04:40:49') 5 9]\n",
      "[30.28266 -97.74638 Timestamp('2017-02-04 05:04:58')\n",
      " Timedelta('0 days 05:04:58') 5 10]\n",
      "[30.258917 -97.7385 Timestamp('2016-10-08 05:10:21')\n",
      " Timedelta('0 days 05:10:21') 5 10]\n",
      "[30.202583675971976 -97.66659691929816 Timestamp('2017-04-08 05:29:38')\n",
      " Timedelta('0 days 05:29:38') 5 10]\n",
      "[30.317225 -97.718738 Timestamp('2016-12-24 05:20:25')\n",
      " Timedelta('0 days 05:20:25') 5 10]\n",
      "[30.266798 -97.737569 Timestamp('2016-10-22 05:21:54')\n",
      " Timedelta('0 days 05:21:54') 5 10]\n",
      "[30.19742919999999 -97.6663058 Timestamp('2016-12-03 05:50:40')\n",
      " Timedelta('0 days 05:50:40') 5 11]\n",
      "[30.264971 -97.731591 Timestamp('2016-11-26 06:01:56')\n",
      " Timedelta('0 days 06:01:56') 5 12]\n",
      "[30.266743 -97.745435 Timestamp('2017-02-25 06:19:44')\n",
      " Timedelta('0 days 06:19:44') 5 12]\n",
      "[30.264327007022928 -97.73059979081155 Timestamp('2017-01-07 06:17:25')\n",
      " Timedelta('0 days 06:17:25') 5 12]\n",
      "[30.265366308372176 -97.73009587079287 Timestamp('2017-03-18 06:16:56')\n",
      " Timedelta('0 days 06:16:56') 5 12]\n",
      "[30.266487799999997 -97.74212949999999 Timestamp('2016-10-22 06:12:08')\n",
      " Timedelta('0 days 06:12:08') 5 12]\n",
      "[30.267428 -97.743964 Timestamp('2017-01-28 06:59:35')\n",
      " Timedelta('0 days 06:59:35') 5 13]\n",
      "[30.267554 -97.743935 Timestamp('2016-09-03 07:08:15')\n",
      " Timedelta('0 days 07:08:15') 5 14]\n",
      "[30.278052 -97.771659 Timestamp('2016-09-03 07:14:36')\n",
      " Timedelta('0 days 07:14:36') 5 14]\n",
      "[30.203408 -97.667739 Timestamp('2017-01-14 07:07:32')\n",
      " Timedelta('0 days 07:07:32') 5 14]\n",
      "[30.226024 -97.761291 Timestamp('2017-02-04 07:38:49')\n",
      " Timedelta('0 days 07:38:49') 5 15]\n",
      "[30.322839 -97.703567 Timestamp('2016-09-10 07:57:24')\n",
      " Timedelta('0 days 07:57:24') 5 15]\n",
      "[30.237699 -97.713438 Timestamp('2016-09-10 07:54:04')\n",
      " Timedelta('0 days 07:54:04') 5 15]\n",
      "[30.269899 -97.749398 Timestamp('2017-01-28 07:33:36')\n",
      " Timedelta('0 days 07:33:36') 5 15]\n",
      "[30.266953 -97.742289 Timestamp('2016-11-12 07:31:45')\n",
      " Timedelta('0 days 07:31:45') 5 15]\n",
      "[30.27007 -97.741012 Timestamp('2017-03-11 07:49:53')\n",
      " Timedelta('0 days 07:49:53') 5 15]\n",
      "[30.202664 -97.667403 Timestamp('2017-02-04 07:38:47')\n",
      " Timedelta('0 days 07:38:47') 5 15]\n",
      "[30.267225 -97.739118 Timestamp('2016-10-29 07:49:43')\n",
      " Timedelta('0 days 07:49:43') 5 15]\n",
      "[30.400984 -97.72284 Timestamp('2016-11-12 07:56:02')\n",
      " Timedelta('0 days 07:56:02') 5 15]\n",
      "[30.260829200000003 -97.7382119 Timestamp('2016-11-19 08:17:27')\n",
      " Timedelta('0 days 08:17:27') 5 16]\n",
      "[30.267187 -97.736868 Timestamp('2017-02-25 08:10:23')\n",
      " Timedelta('0 days 08:10:23') 5 16]\n",
      "[30.267606 -97.742766 Timestamp('2017-01-14 08:43:29')\n",
      " Timedelta('0 days 08:43:29') 5 17]\n",
      "[30.267153 -97.736648 Timestamp('2017-01-28 08:53:42')\n",
      " Timedelta('0 days 08:53:42') 5 17]\n",
      "[30.265943 -97.745193 Timestamp('2017-01-14 08:34:48')\n",
      " Timedelta('0 days 08:34:48') 5 17]\n",
      "[30.338716 -97.689945 Timestamp('2017-01-28 09:31:18')\n",
      " Timedelta('0 days 09:31:18') 5 19]\n",
      "[30.268133 -97.736718 Timestamp('2017-01-28 09:31:20')\n",
      " Timedelta('0 days 09:31:20') 5 19]\n",
      "[30.267045557491336 -97.73695964366199 Timestamp('2017-01-21 09:53:14')\n",
      " Timedelta('0 days 09:53:14') 5 19]\n",
      "[30.264053 -97.731942 Timestamp('2017-03-11 10:07:20')\n",
      " Timedelta('0 days 10:07:20') 5 20]\n",
      "[30.282453 -97.736629 Timestamp('2017-04-15 10:40:20')\n",
      " Timedelta('0 days 10:40:20') 5 21]\n",
      "[30.198229889074444 -97.77713879942894 Timestamp('2016-09-10 11:27:20')\n",
      " Timedelta('0 days 11:27:20') 5 22]\n",
      "[30.264016 -97.732322 Timestamp('2016-09-03 11:15:23')\n",
      " Timedelta('0 days 11:15:23') 5 22]\n",
      "[30.343296 -97.729351 Timestamp('2017-02-25 11:56:20')\n",
      " Timedelta('0 days 11:56:20') 5 23]\n",
      "[30.202565 -97.666891 Timestamp('2017-02-25 11:57:13')\n",
      " Timedelta('0 days 11:57:13') 5 23]\n",
      "[30.202671 -97.666891 Timestamp('2017-03-11 11:32:01')\n",
      " Timedelta('0 days 11:32:01') 5 23]\n",
      "[30.293371 -97.745801 Timestamp('2016-12-03 12:25:09')\n",
      " Timedelta('0 days 12:25:09') 5 24]\n",
      "[30.223099 -97.745869 Timestamp('2016-12-03 12:49:01')\n",
      " Timedelta('0 days 12:49:01') 5 25]\n",
      "[30.246804 -97.7506 Timestamp('2017-02-04 13:03:01')\n",
      " Timedelta('0 days 13:03:01') 5 26]\n",
      "[30.248298 -97.734504 Timestamp('2017-04-08 13:51:06')\n",
      " Timedelta('0 days 13:51:06') 5 27]\n",
      "[30.281979 -97.759377 Timestamp('2016-10-08 13:49:20')\n",
      " Timedelta('0 days 13:49:20') 5 27]\n",
      "[30.216568000000002 -97.795464 Timestamp('2016-12-17 14:14:23')\n",
      " Timedelta('0 days 14:14:23') 5 28]\n",
      "[30.319107 -97.721613 Timestamp('2017-02-04 14:14:04')\n",
      " Timedelta('0 days 14:14:04') 5 28]\n",
      "[30.282358 -97.745289 Timestamp('2017-01-21 14:57:34')\n",
      " Timedelta('0 days 14:57:34') 5 29]\n",
      "[30.255884 -97.74585 Timestamp('2017-02-11 14:55:49')\n",
      " Timedelta('0 days 14:55:49') 5 29]\n",
      "[30.256157 -97.705517 Timestamp('2017-03-11 14:48:21')\n",
      " Timedelta('0 days 14:48:21') 5 29]\n",
      "[30.264051199999997 -97.7167144 Timestamp('2017-03-11 14:54:30')\n",
      " Timedelta('0 days 14:54:30') 5 29]\n",
      "[30.258453 -97.789795 Timestamp('2017-03-11 14:57:01')\n",
      " Timedelta('0 days 14:57:01') 5 29]\n",
      "[30.260622 -97.696603 Timestamp('2017-02-25 15:22:33')\n",
      " Timedelta('0 days 15:22:33') 5 30]\n",
      "[30.274555 -97.770135 Timestamp('2016-07-09 15:10:43')\n",
      " Timedelta('0 days 15:10:43') 5 30]\n",
      "[30.278648 -97.715558 Timestamp('2016-09-03 15:57:49')\n",
      " Timedelta('0 days 15:57:49') 5 31]\n",
      "[30.280459 -97.751213 Timestamp('2016-10-08 16:25:25')\n",
      " Timedelta('0 days 16:25:25') 5 32]\n",
      "[30.354594 -97.71808 Timestamp('2016-11-12 16:01:03')\n",
      " Timedelta('0 days 16:01:03') 5 32]\n",
      "[30.313631 -97.710463 Timestamp('2016-11-12 16:00:52')\n",
      " Timedelta('0 days 16:00:52') 5 32]\n",
      "[30.268261 -97.741709 Timestamp('2017-03-11 16:23:10')\n",
      " Timedelta('0 days 16:23:10') 5 32]\n",
      "[30.331646585924904 -97.71457996219397 Timestamp('2017-01-07 16:50:08')\n",
      " Timedelta('0 days 16:50:08') 5 33]\n",
      "[30.346954 -97.747666 Timestamp('2017-03-18 16:49:12')\n",
      " Timedelta('0 days 16:49:12') 5 33]\n",
      "[30.287187 -97.742326 Timestamp('2016-12-03 16:35:26')\n",
      " Timedelta('0 days 16:35:26') 5 33]\n",
      "[30.263370999999996 -97.71501599999999 Timestamp('2017-02-18 16:33:30')\n",
      " Timedelta('0 days 16:33:30') 5 33]\n",
      "[30.261137 -97.731149 Timestamp('2017-02-18 17:29:07')\n",
      " Timedelta('0 days 17:29:07') 5 34]\n",
      "[30.277777 -97.703746 Timestamp('2016-08-06 17:27:19')\n",
      " Timedelta('0 days 17:27:19') 5 34]\n",
      "[30.267747 -97.755017 Timestamp('2016-10-29 17:16:06')\n",
      " Timedelta('0 days 17:16:06') 5 34]\n",
      "[30.27795 -97.793083 Timestamp('2016-10-22 17:04:15')\n",
      " Timedelta('0 days 17:04:15') 5 34]\n",
      "[30.287716 -97.773315 Timestamp('2016-10-22 17:04:24')\n",
      " Timedelta('0 days 17:04:24') 5 34]\n",
      "[30.20543171630524 -97.78637163341045 Timestamp('2017-03-18 17:19:03')\n",
      " Timedelta('0 days 17:19:03') 5 34]\n",
      "[30.217635 -97.782897 Timestamp('2017-03-18 17:20:00')\n",
      " Timedelta('0 days 17:20:00') 5 34]\n",
      "[30.287776 -97.772274 Timestamp('2017-03-18 17:18:07')\n",
      " Timedelta('0 days 17:18:07') 5 34]\n",
      "[30.31662 -97.709791 Timestamp('2017-03-18 17:02:54')\n",
      " Timedelta('0 days 17:02:54') 5 34]\n",
      "[30.24472 -97.764116 Timestamp('2016-09-17 17:20:45')\n",
      " Timedelta('0 days 17:20:45') 5 34]\n",
      "[30.237341 -97.751966 Timestamp('2017-01-21 17:24:14')\n",
      " Timedelta('0 days 17:24:14') 5 34]\n",
      "[30.23857 -97.790265 Timestamp('2016-10-29 17:14:41')\n",
      " Timedelta('0 days 17:14:41') 5 34]\n",
      "[30.258581 -97.746886 Timestamp('2017-03-18 17:13:41')\n",
      " Timedelta('0 days 17:13:41') 5 34]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_rides(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.26128253 -97.74291888]\n",
      " [ 30.30877832 -97.72537264]\n",
      " [ 30.23537192 -97.78780446]\n",
      " [ 30.20242933 -97.66738067]\n",
      " [ 30.39011275 -97.74409875]]\n",
      "{0: [30.261282533129606, -97.742918879333942, 57, 0], 1: [30.308778319999998, -97.725372640000003, 20, 1], 2: [30.235371917774387, -97.787804464786021, 13, 2], 3: [30.202429333333335, -97.667380666666674, 6, 3], 4: [30.39011275, -97.744098750000006, 4, 4]}\n"
     ]
    }
   ],
   "source": [
    "predicted_centroids, predicted_dict = create_centroids(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.26128253  30.30877832  30.23537192  30.20242933  30.39011275]\n",
      "[0.82, 0.45, 0.38, 0.31, 0.29]\n"
     ]
    }
   ],
   "source": [
    "plot_Austin_centroids(predicted_centroids,predicted_dict,len(predictions),unfulfilled_rides=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mapping Rides Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_error(predicted_centroids,actual_centroids):\n",
    "    '''\n",
    "    takes in two sets of centroids and returns the average distance between each predicted centroid and the \n",
    "    closest actual centroid\n",
    "    \n",
    "    input:\n",
    "    -predicted ndarray\n",
    "    -actual ndarray\n",
    "    \n",
    "    output:\n",
    "    -float'''\n",
    "    \n",
    "    distances = []\n",
    "    for cent in predicted_centroids:\n",
    "        closest = 10000\n",
    "        for i in actual_centroids:\n",
    "            if vincenty(cent,i).miles < closest:\n",
    "                closest = vincenty(cent,i).miles\n",
    "        distances.append(closest)\n",
    "    return np.mean(distances)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_at_date(df,datetime):\n",
    "    '''\n",
    "    splits my dataset at anygiven datetime and parses the data into a training set of all rides that come before,\n",
    "    and the next 30 minutes \n",
    "    \n",
    "    input:\n",
    "    -Dataframe (all data)\n",
    "    - datetime obj (split location)\n",
    "    \n",
    "    output: \n",
    "    -X: dataframe\n",
    "    -X_test: dataframe\n",
    "    '''\n",
    "    datetime = pd.DataFrame([datetime], columns=['created_date'])\n",
    "    df1 = df[df['created_date']<=datetime['created_date'].iloc[0]]\n",
    "    df2 = df[(df['created_date']>=datetime['created_date'].iloc[0])&(df['created_date']<=datetime['created_date'].iloc[0]+pd.Timedelta('30 minute'))]\n",
    "    return df1,df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressor for n_rides in a timeblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfreg = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfreg['month']= dfreg['created_date'].dt.month\n",
    "dfreg['day'] = dfreg['created_date'].dt.day\n",
    "dfreg['day_of_week'] = dfreg['created_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a COUNT response variable\n",
    "dfreg = dfreg.groupby(['day_of_week','period', 'month','day'])['start_location_lat'].count().reset_index(name=\"count\")\n",
    "#dfreg = pd.get_dummies(dfreg, columns=['day_of_week'], drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = dfreg.pop('count')\n",
    "X = dfreg\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for rf1: [-23.99056186 -22.80092167 -26.01468162]\n"
     ]
    }
   ],
   "source": [
    "rf1 = RandomForestRegressor(n_estimators=100)\n",
    "score = cross_val_score(rf1, X_train, y_train, scoring='neg_mean_absolute_error')\n",
    "print 'accuracy for rf1:', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf1.fit(X_train,y_train)\n",
    "predictions = rf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.694990312759479"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datetime = pd.to_datetime('2016-10-09 11:00:00')\n",
    "d1,d2 = split_at_date(df,datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building functions to test model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_df(data):\n",
    "    '''\n",
    "    takes in dataframe of raw data and cleans it so that it can be passed into my model to predict n_rides for\n",
    "    the next half-hour block.\n",
    "    \n",
    "    input:\n",
    "    -dataframe\n",
    "    \n",
    "    output:\n",
    "    -X dataframe\n",
    "    -y dataframe'''\n",
    "    data['month']= data['created_date'].dt.month\n",
    "    data['day'] = data['created_date'].dt.day\n",
    "    data['day_of_week'] = data['created_date'].dt.weekday\n",
    "    # creating a COUNT response variable\n",
    "    data = data.groupby(['day_of_week','period','day'])['start_location_lat'].count().reset_index(name=\"count\")\n",
    "    #data = pd.get_dummies(data, columns=['day_of_week'], drop_first = True)\n",
    "    y = data.pop('count')\n",
    "    X = data\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_n_rides(data,datetime):\n",
    "    '''\n",
    "    takes in data and a split datetime and predicts how many n_rides there will be for the next half hour.\n",
    "    \n",
    "    input:\n",
    "    - data (dataframe)\n",
    "    - datime (string or datetime obj)\n",
    "    \n",
    "    output:\n",
    "    -int'''\n",
    "    data,response = prep_df(data)\n",
    "    rf1 = RandomForestRegressor(n_estimators=100)\n",
    "    model = rf1.fit(data,response)\n",
    "    data2, response2 = prep_df(d2)\n",
    "    return model.predict(data2).astype(int)[0] #return prediction as integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model: 100 random dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_mean_dif_distribution(df):\n",
    "    '''\n",
    "    testing my model to find where the mean distance-error is. Use this distribution to create a hypo test to find \n",
    "    where the true mean is.\n",
    "    \n",
    "    input:\n",
    "    none\n",
    "    \n",
    "    output:\n",
    "    list of floats.'''\n",
    "    errors = []\n",
    "    for x in xrange(100):\n",
    "        #define parameters:\n",
    "        date = random_date()\n",
    "        dated = pd.to_datetime(date)\n",
    "        before,after = split_at_date(df,dated)\n",
    "        if len(after) <= 5:\n",
    "            continue\n",
    "        print 'date working: %s' %(date)\n",
    "        \n",
    "        # test_centroids:\n",
    "        test_centroids = create_centroids(after)\n",
    "        print 'test_centroids_working'\n",
    "        \n",
    "        #train_centroids:\n",
    "        predictions = predict_rides(before)\n",
    "        train_centroids = create_centroids(predictions)\n",
    "        print'train_centroids_working with %s predicted rides' %(len(predictions))\n",
    "        \n",
    "        #find error:\n",
    "        error = distance_error(train_centroids[0], test_centroids[0])\n",
    "        errors.append(error)\n",
    "        print 'completed error! %s' %(error)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_date():\n",
    "    year = 2016\n",
    "    month = random.randint(1, 12)\n",
    "    day = random.randint(1, 28)\n",
    "    hour = random.randint(0,23)\n",
    "    minute = random.randrange(0,31,30)\n",
    "    return '2016-%s-%s %s:%s:00' %(month,day,hour,minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date working: 2016-10-11 0:0:00\n",
      "test_centroids_working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_centroids_working with 42 predicted rides\n",
      "completed error! 0.894664119923\n",
      "date working: 2016-9-22 17:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 30 predicted rides\n",
      "completed error! 1.1316871335\n",
      "date working: 2016-9-22 2:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 30 predicted rides\n",
      "completed error! 1.84728285287\n",
      "date working: 2016-10-15 10:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 39 predicted rides\n",
      "completed error! 1.19164868032\n",
      "date working: 2016-10-24 19:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 40 predicted rides\n",
      "completed error! 1.16516577379\n",
      "date working: 2016-9-6 4:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 30 predicted rides\n",
      "completed error! 1.80750547576\n",
      "date working: 2016-9-16 13:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 30 predicted rides\n",
      "completed error! 1.83333919823\n",
      "date working: 2016-11-7 12:30:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 41 predicted rides\n",
      "completed error! 1.69110030854\n",
      "date working: 2016-9-3 3:0:00\n",
      "test_centroids_working\n",
      "train_centroids_working with 30 predicted rides\n",
      "completed error! 1.39412442786\n",
      "date working: 2016-8-11 11:0:00\n",
      "test_centroids_working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/William/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-579-e8e2fb9f044c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mean_dif_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-567-7a459472ec4c>\u001b[0m in \u001b[0;36mcreate_mean_dif_distribution\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#train_centroids:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_rides\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_centroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m'train_centroids_working with %s predicted rides'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-578-f63060854675>\u001b[0m in \u001b[0;36mpredict_rides\u001b[0;34m(input_dataframe)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_rides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_ride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/William/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   2642\u001b[0m                              \"provide positive value.\")\n\u001b[1;32m   2643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2644\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice (numpy/random/mtrand/mtrand.c:17062)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0"
     ]
    }
   ],
   "source": [
    "errors = create_mean_dif_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
